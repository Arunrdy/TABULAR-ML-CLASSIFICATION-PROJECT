# ğŸš€ TABULAR-ML-CLASSIFICATION-PROJECT

A simple, clear, and beginner-friendly machine-learning classification system for tabular datasets.  
Upload CSV/Excel or pre-saved NumPy arrays, preprocess, train ML models, evaluate performance, and make predictions through a minimal Flask web UI.

---

## ğŸ“Œ Quick Highlights
- Minimal Flask web interface (upload â†’ train â†’ predict)  
- Supports CSV/Excel and NumPy `.npy` files  
- Preprocessing + training pipeline (scikit-learn / XGBoost used in this repo)  
- Trained models and scalers saved to `models/`  
- Figures saved to `figures/` for inspection

---

## ğŸ”— Repository
ğŸ‘‰ **GitHub:** https://github.com/Arunrdy/TABULAR-ML-CLASSIFICATION-PROJECT

## âš™ï¸ Install & Run (short)
```bash
git clone https://github.com/Arunrdy/TABULAR-ML-CLASSIFICATION-PROJECT.git
cd TABULAR-ML-CLASSIFICATION-PROJECT

python3 -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate

pip install -r requirements.txt
python app.py
```

Open in browser:  
ğŸ‘‰ https://tabular-ml-classification-project-ev6n.onrender.com


## ğŸ¯ How to use (summary)
1. Open the web UI.  
2. Upload CSV/Excel **or** use `.npy` files already present.  
3. Select the target column (if CSV) or choose `y.npy`.  
4. Train and view accuracy / evaluation metrics.  
5. Inspect saved figures and models as needed.

---

## ğŸ“‚ Exact Project Structure â€” **ANALYZED FROM YOUR LATEST SCREENSHOT**  
I inspected the screenshot you provided and updated the structure to match exactly whatâ€™s visible. **No invented filenames** beyond what is shown. If a filename below looks like a typo (see note), you can rename it in your repo.

```
TABULAR-ML-CLASSIFICATION-PROJECT/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.csv          # (visible)
â”‚   â”œâ”€â”€ X_test.npy           # (visible)
â”‚   â”œâ”€â”€ X_train.npy          # (visible)
â”‚   â”œâ”€â”€ X.npy                # (visible)
â”‚   â”œâ”€â”€ y_test.npy           # (visible)
â”‚   â”œâ”€â”€ y_train.npy          # (visible)
â”‚   â””â”€â”€ y.npy                # (visible)
â”‚
â”œâ”€â”€ figures/                 # (visible)
â”‚   â”œâ”€â”€ confusion_baseline.png   # (visible)
â”‚   â”œâ”€â”€ featimp_baseline.png     # (visible) â€” filename in screenshot uses "featimp"
â”‚   â””â”€â”€ shap_summary.png         # (visible)
â”‚
â”œâ”€â”€ models/                  # (visible)
â”‚   â”œâ”€â”€ scaler_5_features.pkl # (visible)
â”‚   â”œâ”€â”€ xgb_5_features.pkl    # (visible)
â”‚   â”œâ”€â”€ xgb_baseline.pkl      # (visible)
â”‚   â””â”€â”€ xgb_improved.pkl      # (visible)
â”‚
â”œâ”€â”€ src/                     # (visible)
â”‚   â”œâ”€â”€ evaluate.py               # (visible)
â”‚   â”œâ”€â”€ improve_and_shap.py       # (visible)
â”‚   â”œâ”€â”€ inspect_data.py           # (visible)
â”‚   â”œâ”€â”€ preprocess.py             # (visible; screenshot shows preprocessing script) 
â”‚   â””â”€â”€ train.py                  # (visible)
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css             # (folder visible; file not shown in screenshot but expected)
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # (folder visible; file not shown in screenshot but expected)
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ test_model_file.py
```

**Notes & small clarifications from the screenshot analysis**
- The `data/` folder (in the screenshot) contains `dataset.csv` and the `.npy` arrays â€” I moved those into `data/` in this listing to match the visual layout you showed.
- The figures list exactly matches the three image files visible: `confusion_baseline.png`, `featimp_baseline.png` (screenshot shows `featimp` â€” I preserved that exact spelling), and `shap_summary.png`.
- The `models/` folder contains four files visible in the screenshot; I listed all four exactly.
- The `src/` folder lists five Python files visible in the screenshot: `evaluate.py`, `improve_and_shap.py`, `inspect_data.py`, `preprocess.py`, and `train.py`.  
  - If your local filename differs (e.g., you suspect `preprocess.py` was spelled with an extra letter in the IDE), I preserved the common/correct spelling `preprocess.py` here and recommend you confirm the actual repo filename and update if needed.

---

## âš ï¸ Limitations
- Interface and preprocessing are minimal by design.  
- Intended for small-to-medium datasets and prototyping.

---

## ğŸ”® Future Enhancements
- Add extra model types (RandomForest, LightGBM) and CV/hyperparameter tuning.  
- Add API endpoints for prediction (e.g., `POST /predict`).  
- Export evaluation reports (CSV) and extended EDA visuals.

---

â­ If you find this project helpful, consider starring the repository.
